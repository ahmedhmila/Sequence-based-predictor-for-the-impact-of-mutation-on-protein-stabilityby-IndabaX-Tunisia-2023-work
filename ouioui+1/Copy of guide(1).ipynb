{"cells":[{"cell_type":"code","source":["#@title Download data from GCP bucket\n","import sys\n","\n","if 'google.colab' in sys.modules:\n","  !gsutil -m cp -r gs://indaba-data .\n","else:\n","  !mkdir -p indaba-data/train\n","  !wget -P indaba-data/train https://storage.googleapis.com/indaba-data/train/train.csv --continue\n","  !wget -P indaba-data/train https://storage.googleapis.com/indaba-data/train/train_mut.pt --continue\n","  !wget -P indaba-data/train https://storage.googleapis.com/indaba-data/train/train_wt.pt --continue\n","\n","  !mkdir -p indaba-data/test\n","  !wget -P indaba-data/test https://storage.googleapis.com/indaba-data/test/test.csv --continue\n","  !wget -P indaba-data/test https://storage.googleapis.com/indaba-data/test/test_mut.pt --continue\n","  !wget -P indaba-data/test https://storage.googleapis.com/indaba-data/test/test_wt.pt --continue"],"metadata":{"id":"DEk5q0rhjBWZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683997965937,"user_tz":-120,"elapsed":94101,"user":{"displayName":"Hamza Labidi","userId":"13160711510787677017"}},"outputId":"b997920b-1a54-4835-db95-6d7f0dd3c285"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Copying gs://indaba-data/test/test_mut.pt...\n","/ [0 files][    0.0 B/  9.3 MiB]                                                \rCopying gs://indaba-data/README.txt...\n","Copying gs://indaba-data/test/test.csv...\n","Copying gs://indaba-data/train/train.csv...\n","Copying gs://indaba-data/train/train_wt.pt...\n","Copying gs://indaba-data/train/train_mut.pt...\n","Copying gs://indaba-data/test/test_wt.pt...\n","==> NOTE: You are downloading one or more large file(s), which would\n","run significantly faster if you enabled sliced object downloads. This\n","feature is enabled by default but requires that compiled crcmod be\n","installed (see \"gsutil help crcmod\").\n","\n"]}]},{"cell_type":"code","source":["#@title Imports and moving to working directory\n","import torch \n","import pandas as pd\n","from tqdm import tqdm\n","\n","# move to data folder\n","%cd indaba-data"],"metadata":{"id":"Jvd8ERpgTvji","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c179ae7a-6911-45e0-bfc6-2311629febd1","executionInfo":{"status":"ok","timestamp":1683998080990,"user_tz":-120,"elapsed":4587,"user":{"displayName":"Hamza Labidi","userId":"13160711510787677017"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/indaba-data\n"]}]},{"cell_type":"code","source":["# Load Embedding tensors & Traing csv\n","# Embeddings were calculated using the ESM 650M pretrained model \n","# Tensor shape of embedded data:  [data_len,1280] \n","# There are no sequences in the Embedding tensors as we've performed an average of it (torch.mean(embed, dim=1))\n","# More details in https://huggingface.co/facebook/esm2_t33_650M_UR50D\n","\n","wt_emb = torch.load(\"train/train_wt.pt\")\n","mut_emb = torch.load(\"train/train_mut.pt\")\n","df = pd.read_csv(\"train/train.csv\")"],"metadata":{"id":"36ZgVoj5odV4","executionInfo":{"status":"ok","timestamp":1683998087196,"user_tz":-120,"elapsed":3859,"user":{"displayName":"Hamza Labidi","userId":"13160711510787677017"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# [Recommended] Split data into train and validation \n","#TODO"],"metadata":{"id":"zr0Njii0pRvN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Building the dataset class\n","class EmbeddingDataset(torch.utils.data.Dataset):\n","  def __init__(self,mut_pt, wt_pt, data_df):\n","    self.pt_mut = mut_pt\n","    self.pt_wt = wt_pt\n","    self.df = data_df\n","  \n","  def __len__(self):\n","      return self.pt_mut.shape[0]\n","\n","  def __getitem__(self, index):\n","    o1=self.pt_mut[index,:]\n","    o2=self.pt_wt[index,:]\n","    if \"ddg\" in self.df:\n","      df_out=torch.Tensor([self.df[\"ddg\"][index]])\n","    else:\n","      df_out=torch.Tensor([self.df[\"ID\"][index]])\n","    return  self.pt_mut[index,:],self.pt_wt[index,:],df_out "],"metadata":{"id":"BEEH-ZWJgdUv","executionInfo":{"status":"ok","timestamp":1684001258239,"user_tz":-120,"elapsed":496,"user":{"displayName":"Hamza Labidi","userId":"13160711510787677017"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# creating training dataset and dataloader\n","train_dataset = EmbeddingDataset(wt_emb, mut_emb, df)\n","# preparing a dataloader for the training\n","train_dataloader = torch.utils.data.dataloader.DataLoader(\n","        train_dataset,\n","        batch_size=32,\n","        shuffle=False,\n","        num_workers=2,\n","    )\n","# [Recommended] Use Data validation loader too\n"],"metadata":{"id":"RrRVCI8siRfF","executionInfo":{"status":"ok","timestamp":1684001383510,"user_tz":-120,"elapsed":467,"user":{"displayName":"Hamza Labidi","userId":"13160711510787677017"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["for i in range(5):  # change the number as needed\n","    print(train_dataset[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XeymjaiKTgfG","executionInfo":{"status":"ok","timestamp":1684001644125,"user_tz":-120,"elapsed":9,"user":{"displayName":"Hamza Labidi","userId":"13160711510787677017"}},"outputId":"104d2484-3c3f-4eba-f95e-315e8e61dde4"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([-0.0632,  1.8905,  1.0130,  ...,  1.7288, -2.4825,  0.3187]), tensor([ 0.0070,  1.9001,  1.0074,  ...,  1.6119, -2.3543,  0.3594]), tensor([0.2288]))\n","(tensor([-0.0632,  1.8905,  1.0130,  ...,  1.7288, -2.4825,  0.3187]), tensor([ 0.0423,  1.9433,  0.9595,  ...,  1.7695, -2.4142,  0.3128]), tensor([0.4969]))\n","(tensor([-0.0632,  1.8905,  1.0130,  ...,  1.7288, -2.4825,  0.3187]), tensor([ 0.0293,  1.9336,  1.0884,  ...,  1.6638, -2.3769,  0.3196]), tensor([0.1630]))\n","(tensor([-0.0632,  1.8905,  1.0130,  ...,  1.7288, -2.4825,  0.3187]), tensor([-0.1233,  2.0180,  1.0377,  ...,  1.6911, -2.2926,  0.3670]), tensor([0.2090]))\n","(tensor([-0.0632,  1.8905,  1.0130,  ...,  1.7288, -2.4825,  0.3187]), tensor([ 0.0676,  1.9103,  1.0881,  ...,  1.6339, -2.3799,  0.2853]), tensor([0.4076]))\n"]}]},{"cell_type":"code","source":["len(train_dataset)"],"metadata":{"id":"B7F-KRZNWmaS","executionInfo":{"status":"ok","timestamp":1684002212278,"user_tz":-120,"elapsed":10,"user":{"displayName":"Hamza Labidi","userId":"13160711510787677017"}},"outputId":"4cc71347-140e-470a-d315-24ccf956c70f","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["339778"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# Building a simple pytorch model\n","# A dummy model (2-param) that demonstrates the usage of the dataset\n","\n","class StabilityModel(torch.nn.Module):\n","  def __init__(self):\n","    super(StabilityModel, self).__init__()\n","    self.lin = torch.nn.Linear(1,1)\n","\n","  def forward(self, x, y):\n","    # run the forward pass\n","    # output should be the stability estimation [batch,estim]\n","    return self.lin(torch.mean(x-y,dim=1).reshape(-1,1)) "],"metadata":{"id":"9NuUlQRK8gHF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example of training script\n","device = torch.device(\"cuda\")\n","model =  StabilityModel().to(device)\n","optimizer = torch.optim.Adadelta(model.parameters(), lr=0.0001)\n","criterion = torch.nn.MSELoss()\n","epoch_loss = 0\n","for i in range(1):\n","  epoch_loss = 0\n","  for batch_idx, (data_mut,data_wt , target) in tqdm(enumerate(train_dataloader)):\n","      # extract input from datallader\n","      x1 = data_wt.to(device)\n","      x2 = data_mut.to(device)\n","      y = target.to(device)\n","      # make prediction\n","      y_pred = model(x1,x2)\n","      # calculate loss and run optimizer\n","      loss = torch.sqrt(criterion(y, y_pred))\n","      loss.backward()\n","      optimizer.step()\n","      epoch_loss += loss\n","  print(\"epoch_\",i,\" = \", epoch_loss/len(train_dataloader))\n","  # [Recommended] Save trained models to select best checkpoint for prediction (or add prediction in the epochs loop)"],"metadata":{"id":"ndGfhMrjlmUE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"09c5d22f-5085-4ed6-9295-caafb55fee00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["10619it [00:49, 213.80it/s]"]},{"output_type":"stream","name":"stdout","text":["epoch_ 0  =  tensor(1.1049, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## Prediction & submission"],"metadata":{"id":"9GDKutS_nKOT"}},{"cell_type":"code","source":["# load embedding tensors & traing csv\n","wt_test_emb = torch.load(\"test/test_wt.pt\")\n","mut_test_emb = torch.load(\"test/test_mut.pt\")\n","df_test = pd.read_csv(\"test/test.csv\")"],"metadata":{"id":"ave_DDMp8fo9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creating testing dataset and loading the embedding\n","test_dataset = EmbeddingDataset(wt_test_emb,mut_test_emb,df_test)\n","# preparing a dataloader for the testing\n","test_dataloader = torch.utils.data.dataloader.DataLoader(\n","        test_dataset,\n","        batch_size=32,\n","        shuffle=False,\n","        num_workers=2,\n","    )"],"metadata":{"id":"9Xmav2yhm_Di"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_result = pd.DataFrame()\n","with torch.no_grad():\n","  for batch_idx, (data_mut,data_wt , target) in tqdm(enumerate(test_dataloader)):\n","    x1 = data_wt.to(device)\n","    x2 = data_mut.to(device)\n","    id = target.to(device)\n","    # make prediction\n","    y_pred = model(x1,x2)\n","    df_result = pd.concat([df_result, pd.DataFrame({\"ID\":id.squeeze().cpu().numpy().astype(int) , \"ddg\" : y_pred.squeeze().cpu().numpy()})])"],"metadata":{"id":"DiylsXvjqOul","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fa1702b8-dc80-4d4d-f22c-0f764d9fde96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["60it [00:00, 157.50it/s]\n"]}]},{"cell_type":"code","source":["df_result.to_csv(\"submission.csv\",index=False)"],"metadata":{"id":"FPm-a2USexgw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7PGmPkRmezal"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}